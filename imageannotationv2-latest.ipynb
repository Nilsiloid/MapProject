{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6841064,"sourceType":"datasetVersion","datasetId":3668476},{"sourceId":7035567,"sourceType":"datasetVersion","datasetId":4047467}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n!pip install roboflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-09T16:47:38.762157Z","iopub.execute_input":"2023-11-09T16:47:38.762880Z","iopub.status.idle":"2023-11-09T16:48:18.163877Z","shell.execute_reply.started":"2023-11-09T16:47:38.762835Z","shell.execute_reply":"2023-11-09T16:48:18.162627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from roboflow import Roboflow\nrf = Roboflow(api_key=\"dyPJst8tgBLfjP9jKEqK\")\nproject = rf.workspace().project(\"mapproject\")\n\nmodel = project.version(4).model\n\n# image_files = [f for f in os.listdir(path=\"/kaggle/input/dv-pe/imgs_to_be_annotated/imgs_to_be_annotated\") if f.endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n# os.mkdir(\"/kaggle/working/annotated\")\n\n# model = project.version(5)\n# model.train()\n\n# dataset = project.version(5).download(\"yolov5\")\n# python train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt","metadata":{"execution":{"iopub.status.busy":"2023-11-09T16:48:18.166132Z","iopub.execute_input":"2023-11-09T16:48:18.166448Z","iopub.status.idle":"2023-11-09T16:48:19.219615Z","shell.execute_reply.started":"2023-11-09T16:48:18.166418Z","shell.execute_reply":"2023-11-09T16:48:19.218653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_files = [f for f in os.listdir(path=\"/kaggle/input/dv-pe/imgs_to_be_annotated/imgs_to_be_annotated/\") if f.endswith(('.png'))]\naccuracy_imgs = [f for f in os.listdir(path=\"/kaggle/input/dv-pe/accuracy_images\") if f.endswith(('.png'))]\n\n# os.mkdir(\"/kaggle/working/accuracy_images_annotated\")\n\n# text_path = \"/kaggle/working/accuracy_values.txt\"\ntext_path_2 = \"/kaggle/working/predictions.txt\"\n\n# with open(text_path, 'w') as f:\n#     f.write(\"---------------------\\n\")\n# f.close()\n\nwith open(text_path_2, 'w') as f2:\n    f2.write(\"---------------------\\n\")\nf2.close()\n    \ni=1\n\nfor img in accuracy_imgs:\n    source_path = \"/kaggle/input/dv-pe/accuracy_images/\" + img\n    prediction = model.predict(source_path, confidence=40, overlap=30)\n    \n    file_num = img[4:-4]\n    pred_name = \"prediction_\"+file_num+\".jpg\"\n    \n    bounding_box = str(prediction[0]['class_id']) + \" \" + str(prediction[0]['x']) + \" \" + str(prediction[0]['y']) + \" \" + str(prediction[0]['width']) + \" \" + str(prediction[0]['height']) + \"\\n\"\n    bounding_box += pred_name + \" \" + str(prediction[1]['class_id']) + \" \" + str(prediction[1]['x']) + \" \" + str(prediction[1]['y']) + \" \" + str(prediction[1]['width']) + \" \" + str(prediction[1]['height']) + \"\\n\"\n#     bounding_box += pred_name + \" \" + str(prediction[2]['class_id']) + \" \" + str(prediction[2]['x']) + \" \" + str(prediction[2]['y']) + \" \" + str(prediction[2]['width']) + \" \" + str(prediction[2]['height']) + \"\\n\"\n\n    with open(text_path_2, 'a') as f2:\n        f2.write(pred_name+ \" \" + bounding_box)\n        f2.write(\"---------------------\\n\")\n        \n    output_path = \"/kaggle/working/accuracy_images_annotated/\" + pred_name\n#     text = prediction.json()\n    prediction.save(output_path)\n    i+=1\n    \n# for img in image_files:\n#     if(i<=500):\n#         source_path = \"/kaggle/input/dv-pe/imgs_to_be_annotated/imgs_to_be_annotated/\" + img\n#         prediction = model.predict(source_path, confidence=40, overlap=30)\n        \n#         file_num = img[4:-4]\n#         pred_name = \"prediction_\"+file_num+\".jpg\"\n#         with open(text_path, 'a') as f:\n#             f.write(pred_name+\":\\n\")\n#             for j in range(0,len(prediction)):\n#                 f.write(str(prediction[j][\"class\"])+\" - \"+str(prediction[j][\"confidence\"])+\"\\n\")\n                \n#             f.write(\"---------------------\\n\")\n            \n#         with open(text_path_2, 'a') as f2:\n#             f2.write(pred_name+\":\\n\")\n#             f2.write(str(prediction))\n                \n#             f2.write(\"---------------------\\n\")\n#             f2.write(\"---------------------\\n\")\n#             f2.write(\"---------------------\\n\")\n#         output_path = \"/kaggle/working/annotated/\" + pred_name\n# #         with open(text_path, 'a') as f:\n# #             f.write(pred_name+\":\\n\")\n# #             for j in range(0,3):\n# #                 f.write(str(prediction[j][\"class\"])+\" - \"+str(prediction[j][\"confidence\"])+\"\\n\")\n                \n# #             f.write(\"---------------------\\n\")\n#         i+=1\n# #         print(output_path)\n#         prediction.save(output_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T16:50:50.539202Z","iopub.execute_input":"2023-11-09T16:50:50.539882Z","iopub.status.idle":"2023-11-09T16:51:23.762962Z","shell.execute_reply.started":"2023-11-09T16:50:50.539848Z","shell.execute_reply":"2023-11-09T16:51:23.761705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r annotated.zip /kaggle/working/accuracy_images_annotated\n!pip install tensorflow keras-ocr","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:43.273175Z","iopub.execute_input":"2023-11-24T05:22:43.273986Z","iopub.status.idle":"2023-11-24T05:22:58.364687Z","shell.execute_reply.started":"2023-11-24T05:22:43.273955Z","shell.execute_reply":"2023-11-24T05:22:58.363530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport keras_ocr\n\n# Load the detector and recognizer into memory. You can customize these models if needed.\npipeline = keras_ocr.pipeline.Pipeline()\n\n# Provide the path to your image\nimage_path = '/kaggle/input/test-image/map_265.png'\n\n# Get predictions\nimages = keras_ocr.tools.read(image_path)\npredictions = pipeline.recognize(images)\n\n# Display the image with bounding boxes\nfig, axs = plt.subplots(nrows=len(images), figsize=(15, 15))\nkeras_ocr.tools.drawAnnotations(image=images[0], predictions=predictions[0], ax=axs)\nplt.show()\n\n# Extract bounding box coordinates\nfor text_result in predictions[0]:\n    print(\"Text:\", text_result[0])\n    print(\"Bounding Box:\", text_result[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:23:22.625591Z","iopub.execute_input":"2023-11-24T05:23:22.626454Z","iopub.status.idle":"2023-11-24T05:23:34.961658Z","shell.execute_reply.started":"2023-11-24T05:23:22.626418Z","shell.execute_reply":"2023-11-24T05:23:34.960319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}